
Uniform-Cost Search (UCS, 均匀代价搜索):

UCS不考虑启发函数，只根据从起点到当前状态的总代价来选择下一个要扩展的状态。
从起点开始，优先考虑总代价最小的状态。
在提供的图上，UCS会首先选择代价最小的边，即从S到A的边，然后是从S到B的边。接下来，会选择从A到C的边。如此继续，直到找到目标状态或遍历完所有状态。

Greedy Best-First Search (贪婪最佳先搜索):

这种方法只考虑启发函数，不考虑从起点到当前状态的代价。
它总是优先选择启发函数值最小的状态。
在给出的图上，从S开始，首先选择启发值最小的A。然后，从A、B和D中选择启发值最小的D。如此继续，直到找到目标状态或遍历完所有状态。
*A Search (A星搜索)**:

A* 搜索综合了总代价和启发函数来选择下一个要扩展的状态。
它优先选择f值最小的状态，其中f = g + h，g是从起点到当前状态的代价，h是启发函数值。
在提供的图上，A* 首先选择启发值加上路径代价最小的状态。随着搜索的进行，它可能会调整选择，优先考虑那些即使代价稍高但启发值更低的状态，从而找到达到目标状态的最佳路径。
这三种方法在给定的状态图上的搜索顺序可能会有所不同，但A* 搜索通常被认为是最有效的，因为它综合了真实代价和启发函数来指导搜索。

==================================================

深度优先搜索 (DFS): 这种方法会尽可能深地探索搜索树的每一个分支，直到找到解决方案或到达预设的深度限制。

广度优先搜索 (BFS): 这种方法会按层次探索，即首先探索开始状态的所有直接后继，然后再探索这些后继的后继，以此类推。

A*搜索: 是一种启发式搜索，它结合了搜索到目前为止的实际成本和到目标的预估成本（由启发式函数提供）来决定哪个节点应该先被探索。

题目提到了两种A*的启发式函数：一个是完美的，与实际到目标的距离相同；另一个是糟糕的，它与完美的启发式相反。

对于每一种搜索方法，我们都需要考虑两种情况：树搜索和图搜索。树搜索可能会多次展开同一个状态，而图搜索不会展开已经被访问过的状态。

1. DFS Tree Search:

最好情况:
需要精确的最小步找到解决方案。
答案: 最小。
最坏情况:
DFS可能会展开到最大个节点或更多。
答案: 无穷。
2. DFS Graph Search:

最好情况:
与DFS Tree Search相同。
答案: 最小。
最坏情况:
可能访问接近较小个状态。
答案: 较小。
3. BFS Tree Search & BFS Graph Search:

分析:
BFS按层次搜索。为了找到一个确切的20步解决方案，它将展开大约为最大个节点。
答案: 最大。
4. A Tree Search with a perfect heuristic:

分析:
使用完美启发函数，A*搜索将展开的节点数远小于最大。
答案: 最小。
5. A Tree Search with a bad heuristic:

分析:
使用这种方法，A*可能会展开接近最大的节点。
答案: 最大。

==================================================

约束满足问题（Constraint Satisfaction Problems，CSP）：

约束满足问题 (CSP):
CSP是一个由变量、其对应的值域以及约束组成的问题。目标是为每一个变量赋一个值，以满足所有的约束。

N-皇后问题:
这是一个经典的CSP问题，其中N个皇后必须放在NxN的棋盘上，使得没有两个皇后在同一行、同一列或同一对角线上。

变量:
在此问题中，每一列有一个变量，表示在该列中皇后的行位置。

值域 (Domain):
对于每个变量，都有一个可能的值的集合。在这里，每个变量的值域都是{1,2,3,4,5,6}，代表皇后可以放置的行。

前向检查 (Forward Checking):
一种启发式方法，当为一个变量赋值时，会立即检查并修剪其他变量的值域，以移除那些不可能满足约束的值。

最小剩余值 (MRV) 启发式:
选择具有最小可能值数量的变量进行赋值。在存在平局的情况下，选择索引最小的变量。

最少约束值 (LCV) 启发式:
选择对其他变量的值域造成最少约束的值。在存在平局的情况下，可以随机选择或使用其他标准。

回溯搜索 (Backtracking Search):
这是一个用于解决CSP问题的深度优先搜索策略，当当前选择导致未来的约束冲突时，它会撤销其选择。

选择变量：使用MRV启发式选择一个变量。因为我们从V1开始，并且V1已经赋值，我们将选择V2作为下一个变量。

选择值：对于V2，我们使用LCV启发式选择一个值。首先，我们需要知道V1=3对V2的值有哪些约束。显然，V2不能为2或4，因为那些位置与V1在对角线上。V2也不能为3，因为V1已经在那个行上。

前向检查：每当为变量选择一个值时，我们都要检查这个选择对其他变量域的影响。例如，如果我们选择V2=1，那么V3不能为2，V4不能为3，以此类推。

回溯：如果我们为一个变量找不到一个有效的值，或者这个选择导致其他变量的域为空，我们就回溯到上一个变量，并为它尝试另一个值。

==================================================



将命题转换为合取范式（CNF）需要经过几个步骤。以下是如何将一个命题公式转换为CNF的指南：

去除条件句 (Implication)
对于任何形式为 P -> Q 的命题，我们可以将其转化为 ~P V Q。

例如：
P -> Q 变为 ~P V Q

去除双条件句 (Biconditional)
对于任何形式为 P <-> Q 的命题，我们可以将其转化为 (P V ~Q) ^ (~P V Q)。

例如：
P <-> Q 变为 (P V ~Q) ^ (~P V Q)

去除否定的非原子命题
使用德摩根定律将否定从复合命题中移出。

例如：
~(P ^ Q) 变为 ~P V ~Q
~(P V Q) 变为 ~P ^ ~Q

分配 (Distribution)
使用分配律将命题转化为CNF的标准形式。

例如：
P V (Q ^ R) 变为 (P V Q) ^ (P V R)

简化
最后，尽可能简化结果。例如，如果你得到 P V ~P，这就是一个永远为真的语句，可以简化为 True。

==========================================

Min-Max算法：
Min-Max是一种用于决策问题（尤其是对于如国际象棋或井字棋之类的游戏）的算法，它的目标是最大化玩家的得分并最小化对手的得分。

MAX-VALUE：
该函数寻找所有后继状态中的最大值。如果深度达到0，它将返回当前状态的评估分数。否则，它会遍历每一个后继状态并调用MIN-VALUE函数。

MIN-VALUE：
该函数与MAX-VALUE相反，它寻找所有后继状态中的最小值。

这种简单的递归交替在每一层之间最大化和最小化。

Alpha-Beta修剪：
Alpha-Beta修剪是Min-Max算法的一个优化，可以显著减少搜索树的大小。

Alpha：这是到目前为止找到的最佳选择，为Max玩家。
Beta：这是到目前为止找到的最佳选择，为Min玩家。
MAX-VALUE 和 MIN-VALUE与前面的版本相似，但它们也接受alpha和beta作为参数，并使用它们来确定是否有可能的移动会改进当前的最佳已知值。如果一个节点的当前已知最佳值使其成为一个不可行的选择，那么该节点的其他子节点不会被考虑，从而减少了搜索量。

实例：
对于给出的例子，我们可以使用Min-Max和Alpha-Beta修剪来确定游戏的最终价值，以及每个节点的alpha和beta值。例如，从根开始，我们先看左子节点，然后再看右子节点，使用alpha和beta值来确定是否应该继续在当前分支上搜索或剪枝。

总结：

Min-Max算法为给定的决策问题提供了一个框架，可以确定最佳的移动。
Alpha-Beta修剪可以大大减少需要考虑的移动数量，从而加速搜索过程。
这些算法特别适用于棋类游戏，其中玩家轮流移动，并且每一步都有多种可能的移动。

==============================================

CSP – 约束图:

在问题定义中，能够从约束图构造出来是非常重要的。节点代表变量，而边代表二元约束。

CSP – 澳大利亚示例:

变量：WA, NT, Q, NSW, V, SA, T。这些代表澳大利亚的各个区域。
域：每个区域可以被涂成红、绿或蓝三种颜色。
约束：相邻区域必须有不同的颜色。
CSP – 一元约束：

这些约束通过过滤变量的域来处理。
回溯搜索树：

这个搜索树与一般的搜索问题的搜索树不同，在每个层次只考虑一个变量。
数独建模为CSP：

81个变量，每个正方形一个。
每行、每列和每9个方格的约束都是“所有不同”的约束。
N-皇后问题建模为CSP：

目标是在一个N*N的棋盘上放置N个皇后，使它们不相互攻击。
交叉字谜建模为CSP：

每行和每列都是一个变量。
交叉的单词必须匹配，这是约束。
矩形地板规划建模为CSP：

找到一个大矩形中小矩形的不重叠位置。
大学课程调度建模为CSP：

有固定数量的教授和教室、要开设的课程列表以及课程可能的时间段。
每个教授有一套他或她可以教的课程。
在CSP中，我们有一组变量，每个变量有一个可能的值域，以及一组约束条件。目标是为每个变量分配一个值，使得所有的约束都得到满足。

===================================================

无信息搜索：

广度优先搜索（BFS）:

使用队列来处理前沿。
返回最浅的解决方案。
时间和空间复杂度都是指数级的。
如果每一步的代价都是常数，则它是最优的。
均匀成本搜索（UCS）:

基于到目前为止的成本g，使用优先队列处理前沿。
返回最优解。
时间和空间复杂度都是指数级的。
问题：当BFS变成UCS时的情况是什么？
深度优先搜索（DFS）:

使用栈来处理前沿。
可能永远不会结束。
如果它返回一个解决方案，那么这个解决方案既不是最浅的，也不是最优的。
时间复杂度是指数级的，但空间复杂度是多项式级的。
迭代深化搜索（IDS）:

使用栈来处理前沿；对于深度限制，在DFS中进行迭代深化。
返回一个最浅的解决方案，空间为多项式级。
有信息搜索：

使用启发式函数 h(state) 来估计从状态到目标的代价。

（贪心的）最佳先搜索:

根据h的值，使用优先队列来处理前沿。
不是最优的。
A*搜索:

使用基于g+h的优先队列来处理前沿。
如果h是容许的（乐观的，永远不会高估），那么它是最优的。
问题：什么时候A*会变成UCS？
示例：

考虑下面的搜索图，其中S是起始节点，G1、G2和G3是目标状态。弧线标有穿越它们的代价，节点内部显示了到目标的启发式代价。对于以下三种搜索策略，指出哪个目标状态被达到：

(a) 广度优先搜索。
达到的目标：G1或G2或G3

(b) 均匀成本搜索。
达到的目标：G2

(c) A*搜索。
达到的目标：G2

启发式示例：

在一个8x8的国际象棋棋盘上，将一个骑士从左上角移到右下角（棋盘上没有其他棋子）。看看骑士如何移动的图示。提出一个可容许的A*启发式；你可以使用x和y来表示在x轴和y轴上到右下角的距离。

可能的启发式包括：
max(x, y)/2

我们除以2是因为骑士每次可以减少x或y的值2

(x+y)/3

我们除以3是因为骑士每次可以减少x的值2和y的值1，或者反过来。

x/2 + y/2/√5

其中 5 = x1 - x2^2 + y1 - y2^2 = 1^2 + 2^2，等等。
