阅读材料采用通常的结构（基本、预期、高级名称）。每个级别都包含上一个级别的材料。我们已经学习过的章节的阅读内容在期中和期末考试中将保持不变。未来的读数可能会根据我们所涵盖的内容进行调整，但如果是这样的话，一些读数将被删除。  

章节编号基于 AIMA 教科书第 4 版。每个列表条目仅提供附加部分。例如，预期阅读内容包括“基本”下列出的部分以及“预期”下列出的部分。建议高级阅读一些额外的读物。

如果你碰巧有第三版，那么第 12 章（第 4 章）是 13（第 3 版），13 是 14，14 是 15，第 19 章是 18，并且没有深度学习的第 21 章。 

第一章简介 

基础： 第 1.1节、  1.4 节和摘要
预期：  1.1、1.2、1.5 _  _ _ 
高级：  1.3、书目和历史注释
阅读图灵关于“计算机器与智能”的经典论文
阅读麦卡锡关于“具有常识的程序”的经典论文
第二章 代理人 

基础 ：第 2.1、2.3、2.4 节和 摘要
预期：  2.2
高级：书目和历史注释
熟悉PEAS描述、不同类型的任务环境、代理架构（反射、模型、目标、效用、学习） 

第三章 搜寻 

基础 ：第 3.1、3.2、3.3、3.4.1、3.4.2、3.4.3、3.5.2、3.6.1、3.6.2节 和 摘要_ _  _ _  _ _  _ _  _ _  _  _  _
预计 ：  3.4.4、3.4.5、3.4.6 _  _ _
高级：所有章节，包括参考文献和历史注释
将问题表述为搜索问题：初始状态、动作、转换模型、状态空间、目标测试。理解完整性、最优性、时间复杂度、空间复杂度。无信息搜索策略：BFS、DFS、统一成本、深度有限、迭代加深 DFS（图和树变体）。贪婪最佳优先搜索、A* 搜索和启发式方法作为问题的宽松版本的解决方案。 

第 6 章约束满足问题 

基础：第 6.1节 和 摘要
预期：  6.2（不是 6.2.3、6.2.4、6.2.6）、6.3 
高级：所有章节，包括参考文献和历史注释
知道如何将问题表述为 CSP，将 CSP 连接为搜索、变量、域、约束的特例 

第 7 章 逻辑代理 

基础：第 7.1、7.2、7.3、7.4 节和 摘要
预期：  7.5 
高级：所有章节，包括参考文献和历史注释
使用命题逻辑符号表达问题，理解符号，通过模型检查证明蕴涵，了解定理证明背后的原理以及它与模型检查有何不同，转换为 CNF  

第 8 章 一阶逻辑 

基础：第 8.1、8.2 节、 摘要
预期：  8.3
高级：所有章节，包括参考文献和历史注释
使用 FOL 提出问题，理解符号，尤其是全称量词和存在量词，将英语句子翻译为 FOL 句子，理解通过用特定对象替换量词的变量来生成多个等效句子，理解等式的使用 

期中材料结束 

第 12 章量化不确定性 

基础：第 12.1、12.2、12.3、12.4、12.5、12.6 节、 摘要
预期：（ 与基本相同） 
高级：所有章节，包括参考文献和历史注释
了解基本概率符号、条件概率、使用完全联合分布进行推理、独立性和条件独立性、贝叶斯规则、朴素贝叶斯模型和文本分类

第13章概率推理 

基本： 第 13.1、13.2 节（不是 13.2.1、13.2.2、13.2.3、13.2.4）、 摘要
预计：  13.3、13.4 
高级：所有章节，包括参考文献和历史注释
贝叶斯网络语义、条件概率表、贝叶斯网络中的精确推理、查询/隐藏/证据变量（忽略变量消除）、近似推理（仅直接采样和拒绝采样）

第 14 章随时间推移的概率推理 

基础：第 14.1、14.2 和 14.3 节， 摘要
预期：  14.4 
高级：所有章节，包括参考文献和历史注释
状态、观察、马尔可夫链、马尔可夫假设、转换和传感器模型、推理任务（它们是什么以及它们有何不同）：过滤、预测、平滑、最可能的解释、学习、具有离散观察的隐马尔可夫模型 

第十九章从例子中学习 

基础：第 19.1、19.2 和 19.3 节， 摘要
预计：  19.7.5 
高级：所有章节，包括参考文献和历史注释
学习形式、监督学习公式、假设、偏差-方差权衡、决策树、感知器、支持向量机、泛化、过度拟合 

第 20 章学习概率模型 

基础：第 20.1、20.2.1、20.2.2、20.2.4、19.3 节、 摘要
预期：  20.3   （只是EM的基本思想） 
高级：所有章节，包括参考文献和历史注释
离散和连续模型的最大似然估计、最大后验概率、贝叶斯学习、EM 算法 

第 21 章深度学习 

多层、激活函数和损失函数的基本思想/概念

==================================================
The readings are structured using the usual (basic, expected, advanced designations). Each level include the material for the previous level. The readings of chapters we haver already covered will remain the same for the midterm and final. The future readings might be adjusted depending on what we cover but if that's the case some readings will be removed.  

The section number is based on the 4th edition of the AIMA textbook. Each list entry provides just the additional sections. For example the Expected reading include the sections listed under Basic as well as the sections listed under Expected. Some additional readings are suggested for Advanced.

If you happen to have the 3rd edition then chapter 12 (4th) is 13 (3rd), 13 is 14, and 14 is 15, chapter 19 is 18, and there is no chapter 21 for deep learning. 

CHAPTER 1 INTRODUCTION 

Basic: Sections 1.1, 1.4 and Summary
Expected: 1.1, 1.2, 1.5
Advanced: 1.3, Bibliographical and Historical notes
Read the classic paper by Turing on “Computing Machinery and Intelligence”
Read the classic paper by McCarthy on “Programs with Common Sense
CHAPTER 2 AGENTS 

Basic: Sections 2.1, 2.3, 2.4 and Summary
Expected: 2.2
Advanced: Bibliographical and historical notes
Be familiar with PEAS description, different types of task environments, agent architectures (reflex, model, goal, utility, learning) 

CHAPTER 3 SEARCH 

Basic: Sections 3.1, 3.2, 3.3, 3.4.1, 3.4.2, 3.4.3, 3.5.2, 3.6.1, 3.6.2 and Summary
Expected: 3.4.4, 3.4.5, 3.4.6
Advanced: All the chapter including bibliographical and historical notes
Formulate problems as search problems: initial state, actions, transition model, state space, goal test. Understand completeness, optimality, time complexity, space complexity. Uninformed search strategies: BFS, DFS, Uniform Cost, Depth Limited, Iterative deepening DFS (both graph and tree variants). Greedy best-first search, A* search and heuristics as solutions to relaxed versions of the problem. 

CHAPTER 6 CONSTRAINT SATISFACTION PROBLEMS 

Basic: Sections 6.1 and Summary
Expected: 6.2 (not 6.2.3, 6.2.4, 6.2.6), 6.3 
Advanced: All the chapter including bibliographical and historical notes
Know how to formulate a problem as a CSP, connection of CSP as a special case of search, variables, domains, constraints 

CHAPTER 7 LOGICAL AGENTS 

Basic: Sections 7.1, 7.2, 7.3, 7.4, and Summary
Expected: 7.5 
Advanced: All the chapter including bibliographical and historical notes
Formulate problems using propositional logic notation, understand notation, prove entailment by model checking, understand the principles behind theorem proving and how it is different than model checking, conversion to CNF  

CHAPTER 8 FIRST ORDER LOGIC 

Basic: Sections 8.1, 8.2, Summary
Expected: 8.3
Advanced: All the chapter including bibliographical and historical notes
Formulate problems using FOL, understand notation especially the universal and existential quantifiers, translate English sentence to FOL sentences, understand the generation of multiple equivalent sentences by substitution of variables with specific objects for the quantifiers, understand the use of equality 

END OF MIDTERM MATERIAL 

CHAPTER 12 Quantifying uncertainty 

Basic: Sections 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, Summary
Expected: (same as basic) 
Advanced: All the chapter including bibliographical and historical notes
Understand basic probability notation, conditional probability, inference using full joint distribution, independence and conditional independance, Bayes' rule, Naive Bayes Models and text classification

CHAPTER 13 Probabilistic Reasoning 

Basic: Sections 13.1, 13.2 (not 13.2.1, 13.2.2, 13.2.3, 13.2.4), Summary
Expected: 13.3, 13.4 
Advanced: All the chapter including bibliographical and historical note
Semantics of Bayesian networks, conditional probability tables, exact inference in Bayesian networks, query/hidden/evidence variables (ignore variable elimination), approximate inference (just direct sampling and rejection sampling)

CHAPTER 14 Probabilistic Reasoning over time 

Basic: Sections 14.1, 14.2 14.3, Summary
Expected: 14.4 
Advanced: All the chapter including bibliographical and historical notes
States, observations, markov chains, markov assumption, transition and sensor models, inference tasks (what they are and how they are different): filtering, prediction, smoothing, most likely explanation, learning, Hidden Markov Models with discrete observations 

CHAPTER 19 Learning from Examples 

Basic: Sections 19.1, 19.2 19.3, Summary
Expected: 19.7.5 
Advanced: All the chapter including bibliographical and historical notes
Forms of learning, supervised learning formulation, hypotheses, bias-variance tradeoff, decision trees, perceptron, support vector machines, generalization, over-fitting 

CHAPTER 20 Learning Probabilistic Models 

Basic: Sections 20.1, 20.2.1, 20.2.2, 20.2.4,  19.3, Summary
Expected: 20.3  (just the basic idea of EM) 
Advanced: All the chapter including bibliographical and historical notes
maximum likelihood estimation for discrete and continuous models, maximum a posteriori, Bayesian learning, EM-algorithm 

CHAPTER 21 Deep Learning 

 The basic ideas/concepts of multiple layers, activation functions, and loss function
 
==================================================

Uniform-Cost Search (UCS, 均匀代价搜索):

UCS不考虑启发函数，只根据从起点到当前状态的总代价来选择下一个要扩展的状态。
从起点开始，优先考虑总代价最小的状态。
在提供的图上，UCS会首先选择代价最小的边，即从S到A的边，然后是从S到B的边。接下来，会选择从A到C的边。如此继续，直到找到目标状态或遍历完所有状态。

Greedy Best-First Search (贪婪最佳先搜索):

这种方法只考虑启发函数，不考虑从起点到当前状态的代价。
它总是优先选择启发函数值最小的状态。
在给出的图上，从S开始，首先选择启发值最小的A。然后，从A、B和D中选择启发值最小的D。如此继续，直到找到目标状态或遍历完所有状态。

*A Search (A星搜索)**:

A* 搜索综合了总代价和启发函数来选择下一个要扩展的状态。
它优先选择f值最小的状态，其中f = g + h，g是从起点到当前状态的代价，h是启发函数值。
在提供的图上，A* 首先选择启发值加上路径代价最小的状态。随着搜索的进行，它可能会调整选择，优先考虑那些即使代价稍高但启发值更低的状态，从而找到达到目标状态的最佳路径。
这三种方法在给定的状态图上的搜索顺序可能会有所不同，但A* 搜索通常被认为是最有效的，因为它综合了真实代价和启发函数来指导搜索。

==================================================

深度优先搜索 (DFS): 这种方法会尽可能深地探索搜索树的每一个分支，直到找到解决方案或到达预设的深度限制。

广度优先搜索 (BFS): 这种方法会按层次探索，即首先探索开始状态的所有直接后继，然后再探索这些后继的后继，以此类推。

A*搜索: 是一种启发式搜索，它结合了搜索到目前为止的实际成本和到目标的预估成本（由启发式函数提供）来决定哪个节点应该先被探索。

题目提到了两种A*的启发式函数：一个是完美的，与实际到目标的距离相同；另一个是糟糕的，它与完美的启发式相反。

对于每一种搜索方法，我们都需要考虑两种情况：树搜索和图搜索。树搜索可能会多次展开同一个状态，而图搜索不会展开已经被访问过的状态。

1. DFS Tree Search:

最好情况:
需要精确的最小步找到解决方案。
答案: 最小。
最坏情况:
DFS可能会展开到最大个节点或更多。
答案: 无穷。
2. DFS Graph Search:

最好情况:
与DFS Tree Search相同。
答案: 最小。
最坏情况:
可能访问接近较小个状态。
答案: 较小。
3. BFS Tree Search & BFS Graph Search:

分析:
BFS按层次搜索。为了找到一个确切的20步解决方案，它将展开大约为最大个节点。
答案: 最大。
4. A Tree Search with a perfect heuristic:

分析:
使用完美启发函数，A*搜索将展开的节点数远小于最大。
答案: 最小。
5. A Tree Search with a bad heuristic:

分析:
使用这种方法，A*可能会展开接近最大的节点。
答案: 最大。

==================================================

约束满足问题（Constraint Satisfaction Problems，CSP）：

约束满足问题 (CSP):
CSP是一个由变量、其对应的值域以及约束组成的问题。目标是为每一个变量赋一个值，以满足所有的约束。

N-皇后问题:
这是一个经典的CSP问题，其中N个皇后必须放在NxN的棋盘上，使得没有两个皇后在同一行、同一列或同一对角线上。

变量:
在此问题中，每一列有一个变量，表示在该列中皇后的行位置。

值域 (Domain):
对于每个变量，都有一个可能的值的集合。在这里，每个变量的值域都是{1,2,3,4,5,6}，代表皇后可以放置的行。

前向检查 (Forward Checking):
一种启发式方法，当为一个变量赋值时，会立即检查并修剪其他变量的值域，以移除那些不可能满足约束的值。

最小剩余值 (MRV) 启发式:
选择具有最小可能值数量的变量进行赋值。在存在平局的情况下，选择索引最小的变量。

最少约束值 (LCV) 启发式:
选择对其他变量的值域造成最少约束的值。在存在平局的情况下，可以随机选择或使用其他标准。

回溯搜索 (Backtracking Search):
这是一个用于解决CSP问题的深度优先搜索策略，当当前选择导致未来的约束冲突时，它会撤销其选择。

选择变量：使用MRV启发式选择一个变量。因为我们从V1开始，并且V1已经赋值，我们将选择V2作为下一个变量。

选择值：对于V2，我们使用LCV启发式选择一个值。首先，我们需要知道V1=3对V2的值有哪些约束。显然，V2不能为2或4，因为那些位置与V1在对角线上。V2也不能为3，因为V1已经在那个行上。

前向检查：每当为变量选择一个值时，我们都要检查这个选择对其他变量域的影响。例如，如果我们选择V2=1，那么V3不能为2，V4不能为3，以此类推。

回溯：如果我们为一个变量找不到一个有效的值，或者这个选择导致其他变量的域为空，我们就回溯到上一个变量，并为它尝试另一个值。

==================================================



将命题转换为合取范式（CNF）需要经过几个步骤。以下是如何将一个命题公式转换为CNF的指南：

去除条件句 (Implication)
对于任何形式为 P -> Q 的命题，我们可以将其转化为 ~P V Q。

例如：
P -> Q 变为 ~P V Q

去除双条件句 (Biconditional)
对于任何形式为 P <-> Q 的命题，我们可以将其转化为 (P V ~Q) ^ (~P V Q)。

例如：
P <-> Q 变为 (P V ~Q) ^ (~P V Q)

去除否定的非原子命题
使用德摩根定律将否定从复合命题中移出。

例如：
~(P ^ Q) 变为 ~P V ~Q
~(P V Q) 变为 ~P ^ ~Q

分配 (Distribution)
使用分配律将命题转化为CNF的标准形式。

例如：
P V (Q ^ R) 变为 (P V Q) ^ (P V R)

简化
最后，尽可能简化结果。例如，如果你得到 P V ~P，这就是一个永远为真的语句，可以简化为 True。

==========================================

Min-Max算法：
Min-Max是一种用于决策问题（尤其是对于如国际象棋或井字棋之类的游戏）的算法，它的目标是最大化玩家的得分并最小化对手的得分。

MAX-VALUE：
该函数寻找所有后继状态中的最大值。如果深度达到0，它将返回当前状态的评估分数。否则，它会遍历每一个后继状态并调用MIN-VALUE函数。

MIN-VALUE：
该函数与MAX-VALUE相反，它寻找所有后继状态中的最小值。

这种简单的递归交替在每一层之间最大化和最小化。

Alpha-Beta修剪：
Alpha-Beta修剪是Min-Max算法的一个优化，可以显著减少搜索树的大小。

Alpha：这是到目前为止找到的最佳选择，为Max玩家。
Beta：这是到目前为止找到的最佳选择，为Min玩家。
MAX-VALUE 和 MIN-VALUE与前面的版本相似，但它们也接受alpha和beta作为参数，并使用它们来确定是否有可能的移动会改进当前的最佳已知值。如果一个节点的当前已知最佳值使其成为一个不可行的选择，那么该节点的其他子节点不会被考虑，从而减少了搜索量。

实例：
对于给出的例子，我们可以使用Min-Max和Alpha-Beta修剪来确定游戏的最终价值，以及每个节点的alpha和beta值。例如，从根开始，我们先看左子节点，然后再看右子节点，使用alpha和beta值来确定是否应该继续在当前分支上搜索或剪枝。

总结：

Min-Max算法为给定的决策问题提供了一个框架，可以确定最佳的移动。
Alpha-Beta修剪可以大大减少需要考虑的移动数量，从而加速搜索过程。
这些算法特别适用于棋类游戏，其中玩家轮流移动，并且每一步都有多种可能的移动。

==============================================

CSP – 约束图:

在问题定义中，能够从约束图构造出来是非常重要的。节点代表变量，而边代表二元约束。

CSP – 澳大利亚示例:

变量：WA, NT, Q, NSW, V, SA, T。这些代表澳大利亚的各个区域。
域：每个区域可以被涂成红、绿或蓝三种颜色。
约束：相邻区域必须有不同的颜色。
CSP – 一元约束：

这些约束通过过滤变量的域来处理。
回溯搜索树：

这个搜索树与一般的搜索问题的搜索树不同，在每个层次只考虑一个变量。
数独建模为CSP：

81个变量，每个正方形一个。
每行、每列和每9个方格的约束都是“所有不同”的约束。
N-皇后问题建模为CSP：

目标是在一个N*N的棋盘上放置N个皇后，使它们不相互攻击。
交叉字谜建模为CSP：

每行和每列都是一个变量。
交叉的单词必须匹配，这是约束。
矩形地板规划建模为CSP：

找到一个大矩形中小矩形的不重叠位置。
大学课程调度建模为CSP：

有固定数量的教授和教室、要开设的课程列表以及课程可能的时间段。
每个教授有一套他或她可以教的课程。
在CSP中，我们有一组变量，每个变量有一个可能的值域，以及一组约束条件。目标是为每个变量分配一个值，使得所有的约束都得到满足。

===================================================

无信息搜索：

广度优先搜索（BFS）:

使用队列来处理前沿。
返回最浅的解决方案。
时间和空间复杂度都是指数级的。
如果每一步的代价都是常数，则它是最优的。
均匀成本搜索（UCS）:

基于到目前为止的成本g，使用优先队列处理前沿。
返回最优解。
时间和空间复杂度都是指数级的。
问题：当BFS变成UCS时的情况是什么？
深度优先搜索（DFS）:

使用栈来处理前沿。
可能永远不会结束。
如果它返回一个解决方案，那么这个解决方案既不是最浅的，也不是最优的。
时间复杂度是指数级的，但空间复杂度是多项式级的。
迭代深化搜索（IDS）:

使用栈来处理前沿；对于深度限制，在DFS中进行迭代深化。
返回一个最浅的解决方案，空间为多项式级。
有信息搜索：

使用启发式函数 h(state) 来估计从状态到目标的代价。

（贪心的）最佳先搜索:

根据h的值，使用优先队列来处理前沿。
不是最优的。
A*搜索:

使用基于g+h的优先队列来处理前沿。
如果h是容许的（乐观的，永远不会高估），那么它是最优的。
问题：什么时候A*会变成UCS？
示例：

考虑下面的搜索图，其中S是起始节点，G1、G2和G3是目标状态。弧线标有穿越它们的代价，节点内部显示了到目标的启发式代价。对于以下三种搜索策略，指出哪个目标状态被达到：

(a) 广度优先搜索。
达到的目标：G1或G2或G3

(b) 均匀成本搜索。
达到的目标：G2

(c) A*搜索。
达到的目标：G2

启发式示例：

在一个8x8的国际象棋棋盘上，将一个骑士从左上角移到右下角（棋盘上没有其他棋子）。看看骑士如何移动的图示。提出一个可容许的A*启发式；你可以使用x和y来表示在x轴和y轴上到右下角的距离。

可能的启发式包括：
max(x, y)/2

我们除以2是因为骑士每次可以减少x或y的值2

(x+y)/3

我们除以3是因为骑士每次可以减少x的值2和y的值1，或者反过来。

x/2 + y/2/√5

其中 5 = x1 - x2^2 + y1 - y2^2 = 1^2 + 2^2，等等。
